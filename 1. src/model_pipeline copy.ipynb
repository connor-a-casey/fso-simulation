{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Pipeline\n",
    "\n",
    "Input:\n",
    "    - Satellite tracking data\n",
    "    - Satellite slr signal data\n",
    "    - Station sat-imagery weather data\n",
    "Output:\n",
    "    - Record of ALL satellite passes over station, weather a signal was made in that pass, and what the cloud conditons were like at the time of pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/74k69jjd0y74r977spsdpz540000gn/T/ipykernel_746/2565732241.py:3: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.\n",
      "  import pandas_profiling\n"
     ]
    }
   ],
   "source": [
    "# this script generates a reort on the cloud and slr da6ta in line of sight of the stattion\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from datetime import datetime\n",
    "from datetime import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sat_passes(sat_name, start_date, end_date, elev):\n",
    "    # Construct the file path using f-strings\n",
    "    file_path = f\"/Users/eugenerotherham/Documents/AtherasAnalytics/clouds-outage-prediction-main/sat_predictions/satellites/{sat_name}/passes_elev{elev}_2022-08_2023-08_df.txt\"\n",
    "    \n",
    "    # Read data directly into DataFrame, specifying date parsing\n",
    "    passes_df = pd.read_csv(file_path, sep='\\t', parse_dates=['time'])\n",
    "    \n",
    "    # Filter by date range using boolean indexing\n",
    "    passes_filtered_df = passes_df[(passes_df['time'] >= start_date) & (passes_df['time'] < end_date)]\n",
    "    \n",
    "    return passes_filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_slr_and_cloud_data(station_code, sat_name, sat_id, start_date, end_date, quarantine_list):\n",
    "    \n",
    "    # 1   IMPORT AND FORMAT SLR AND CLOUD DATA\n",
    "\n",
    "    # read from file cloud and slr data\n",
    "    cloud_df = pd.read_csv('/Users/eugenerotherham/Documents/AtherasAnalytics/clouds-outage-prediction-main/eumetsat_lab/stations/matm_cloud_2022-06_2023-08.txt', sep='\\t')\n",
    "    slr_df = pd.read_csv('/Users/eugenerotherham/Documents/AtherasAnalytics/clouds-outage-prediction-main/slr_data/1yr_data/matm_slr_2022-06_2023-08.txt', sep='\\t')\n",
    "\n",
    "    # cloud data\n",
    "\n",
    "    cloud_df['time'] = pd.to_datetime(cloud_df['time'], format = \"%Y%m%d%H%M%S\")\n",
    "    cloud_df = cloud_df.sort_values(by='time', ascending=True)\n",
    "    cloud_df = cloud_df[['time', 'cloud_cov']]\n",
    "    cloud_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # slr data\n",
    "\n",
    "    slr_df['time'] = pd.to_datetime(slr_df['time'], format='mixed')\n",
    "    slr_df = slr_df.sort_values(by='time', ascending=True)\n",
    "    slr_df['time'] = slr_df['time'].dt.strftime('%Y%m%d%H%M%S')\n",
    "    slr_df['time'] = slr_df['time'].str.rstrip('.')\n",
    "    slr_df['time'] = pd.to_datetime(slr_df['time'])\n",
    "\n",
    "    new_slr_df = slr_df[['time', 'receive_amp', 'sat_id']].copy()\n",
    "\n",
    "    new_slr_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # 2   AGGREGATE SLR BASED ON SPECIFIC SATELLITE\n",
    "\n",
    "    sat_slr_df = new_slr_df.copy()\n",
    "    sat_slr_df = sat_slr_df[(sat_slr_df['sat_id'] == sat_id)]\n",
    "    sat_slr_df.set_index('time', inplace=True)\n",
    "\n",
    "    resampled_df = sat_slr_df.resample('15T').agg({'receive_amp': ['mean', 'std']})\n",
    "\n",
    "    sat_slr_df = pd.DataFrame({\n",
    "        'mean_receive_amp': resampled_df['receive_amp']['mean'],\n",
    "        'std_receive_amp': resampled_df['receive_amp']['std']\n",
    "    })\n",
    "    sat_slr_df = sat_slr_df[(sat_slr_df.index >= '2022-08-01') & (sat_slr_df.index < '2023-08-01')]\n",
    "\n",
    "    date_range = pd.date_range(start='2022-08-01', end='2023-08-01', freq='15T')\n",
    "    date_df = pd.DataFrame({'time': date_range})\n",
    "\n",
    "    slr_merged_df = pd.merge(date_df, sat_slr_df, left_on='time', right_index=True, how='left')\n",
    "\n",
    "    # 3   MERGE SLR AND CLOUD DATA - SAVE TO FILE\n",
    "\n",
    "    merged_df = pd.merge(slr_merged_df, cloud_df, on='time', how='inner')\n",
    "    merged_df = merged_df[['time', 'mean_receive_amp',  'std_receive_amp', 'cloud_cov']]\n",
    "    merged_df.to_csv(f\"/Users/eugenerotherham/Documents/AtherasAnalytics/clouds-outage-prediction-main/exploration_data_analysis/data/{station_code}/satellites/{sat_name}_2022-08_2023-08_merged.txt\", sep='\\t')\n",
    "\n",
    "    cloud_slr_df = pd.read_csv(f'/Users/eugenerotherham/Documents/AtherasAnalytics/clouds-outage-prediction-main/exploration_data_analysis/data/{station_code}/satellites/{sat_name}_2022-08_2023-08_merged.txt', sep='\\t')\n",
    "    cloud_slr_df = cloud_slr_df[['time', 'mean_receive_amp', 'cloud_cov']].copy()\n",
    "\n",
    "    cloud_slr_df['time'] = pd.to_datetime(cloud_slr_df['time'])\n",
    "    cloud_slr_filtered_df = cloud_slr_df[(cloud_slr_df['time'] >= start_date) & (cloud_slr_df['time'] < end_date)]\n",
    "\n",
    "    # Use .loc to avoid the SettingWithCopyWarning\n",
    "    cloud_slr_filtered_df.loc[:, 'time'] = cloud_slr_filtered_df['time'] + pd.Timedelta(hours=2)\n",
    "    quarantine_days = pd.to_datetime(quarantine_list)\n",
    "    filtered_df = cloud_slr_filtered_df[~cloud_slr_filtered_df['time'].isin(quarantine_days)]\n",
    "\n",
    "    return filtered_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def los_signal_true_false(passes_filtered_df, cloud_slr_filtered_df, sat_name, station_code):\n",
    "    los_data = []\n",
    "\n",
    "    for i in range(0, len(passes_filtered_df), 2):\n",
    "        try:\n",
    "            los_start = passes_filtered_df['time'].iloc[i].strftime('%Y-%m-%d %H:%M:%S')\n",
    "            los_end = passes_filtered_df['time'].iloc[i + 1].strftime('%Y-%m-%d %H:%M:%S')\n",
    "        except IndexError:\n",
    "            print(\"IndexError: No end of pass marker at end_date. Skipping pass...\")\n",
    "            continue\n",
    "\n",
    "        stage_cloud_slr = cloud_slr_filtered_df[\n",
    "            (cloud_slr_filtered_df['time'] >= los_start) & (cloud_slr_filtered_df['time'] <= los_end)\n",
    "        ]\n",
    "\n",
    "        average_cloud_cov = stage_cloud_slr['cloud_cov'].mean()\n",
    "        pass_success = not stage_cloud_slr['mean_receive_amp'].isna().all()\n",
    "\n",
    "        los_data.append({\n",
    "            'station': station_code,\n",
    "            'satellite': sat_name,\n",
    "            'pass_start_date': los_start,\n",
    "            'pass_end_date': los_end,\n",
    "            'mean_cloud': average_cloud_cov,\n",
    "            'pass_success': pass_success\n",
    "        })\n",
    "\n",
    "    los_df = pd.DataFrame(los_data)\n",
    "    return los_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data with elevation angle 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Satellites:   0%|          | 0/35 [00:00<?, ?satellite/s, Current Satellite=galileo210]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Satellites: 100%|██████████| 35/35 [38:57<00:00, 66.79s/satellite, Current Satellite=galileo209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for dataframe finished processing: see /Users/eugenerotherham/Documents/AtherasAnalytics/clouds-outage-prediction-main/exploration_data_analysis/pipeline_results/elev45_model_df.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "from contextlib import ExitStack\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "\n",
    "\n",
    "def main():\n",
    "    elevation_values = [45]\n",
    "    station_code = 'matm'\n",
    "    start_date = '2022-08-01'\n",
    "    end_date = '2023-08-01'\n",
    "\n",
    "    quarantine_list = [\n",
    "        '2023-02-15', '2023-02-16', '2023-02-17', '2023-02-21', '2023-03-06', '2023-03-08', '2023-03-10', '2023-04-26', '2023-05-11', '2023-05-17', \n",
    "        '2023-01-11', '2023-02-09', '2022-06-02', '2022-11-01','2022-12-25', '2022-12-26', '2023-01-01', '2023-01-06', '2023-04-04', '2023-04-25',\n",
    "        '2023-05-01', '2023-05-23']\n",
    "\n",
    "    satellite_folder_path = '/Users/eugenerotherham/Documents/AtherasAnalytics/clouds-outage-prediction-main/sat_predictions/satellites/'\n",
    "\n",
    "    sat_list_path = '/Users/eugenerotherham/Documents/AtherasAnalytics/clouds-outage-prediction-main/sat_predictions/satellite_list_matm_2022-08_2022-08.txt'\n",
    "\n",
    "    with ExitStack() as stack:\n",
    "        sat_list_file = stack.enter_context(open(sat_list_path, 'r'))\n",
    "        sat_list = pd.read_csv(sat_list_file, sep='\\t')\n",
    "\n",
    "        for elev in elevation_values:\n",
    "            print(f'Processing data with elevation angle {elev}')\n",
    "\n",
    "            model_df = pd.DataFrame()\n",
    "\n",
    "            # Add tqdm progress bar for satellites\n",
    "            satellites = os.listdir(satellite_folder_path)\n",
    "            satellites_progress = tqdm(satellites, desc='Satellites', unit='satellite')\n",
    "\n",
    "            for sat_name in satellites_progress:\n",
    "                sat_name_path = os.path.join(satellite_folder_path, sat_name)\n",
    "                if os.path.isdir(sat_name_path):\n",
    "                    satellites_progress.set_postfix({'Current Satellite': sat_name})  # Update progress bar description\n",
    "                    satellites_progress.update()  # Manually update progress bar\n",
    "\n",
    "                    sat_id = sat_list.loc[sat_list['sat_name'] == sat_name, 'sat_id'].values[0]\n",
    "                    passes_filtered_df = get_sat_passes(sat_name, start_date, end_date, elev)\n",
    "                    cloud_slr_filtered_df = get_slr_and_cloud_data(station_code, sat_name, sat_id, start_date, end_date, quarantine_list)\n",
    "                    los_df = los_signal_true_false(passes_filtered_df, cloud_slr_filtered_df, sat_name, station_code)\n",
    "                    model_df = pd.concat([model_df, los_df], ignore_index=True)\n",
    "\n",
    "            satellites_progress.close()  # Close the progress bar\n",
    "\n",
    "            # Convert pass_start_date and pass_end_date to datetime objects in your actual DataFrame (model_elev30)\n",
    "            model_df['pass_start_date'] = pd.to_datetime(model_df['pass_start_date'])\n",
    "            model_df['pass_end_date'] = pd.to_datetime(model_df['pass_end_date'])\n",
    "\n",
    "            # Extract only the date part from the datetime columns in the DataFrame\n",
    "            model_df['pass_start_date_date'] = model_df['pass_start_date'].dt.date\n",
    "            model_df['pass_end_date_date'] = model_df['pass_end_date'].dt.date\n",
    "\n",
    "            # Convert quarantine_list to datetime objects\n",
    "            quarantine_dates = pd.to_datetime(quarantine_list).date\n",
    "\n",
    "            # Filter rows based on quarantine_list\n",
    "            filtered_model_df = model_df[~model_df['pass_start_date_date'].isin(quarantine_dates) & ~model_df['pass_end_date_date'].isin(quarantine_dates)]\n",
    "\n",
    "            filtered_model_df = filtered_model_df.drop(['pass_start_date_date', 'pass_end_date_date'], axis=1)\n",
    "\n",
    "            model_file_path = f'/Users/eugenerotherham/Documents/AtherasAnalytics/clouds-outage-prediction-main/exploration_data_analysis/pipeline_results/elev{elev}_model_df.txt'\n",
    "            filtered_model_df.to_csv(model_file_path, sep='\\t')\n",
    "            print(f'Model for dataframe finished processing: see {model_file_path}')\n",
    "            \n",
    "            # Manually trigger garbage collection to free up memory\n",
    "            gc.collect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIPELINE\n",
    "\n",
    "FEATURES\n",
    "satellite // pass_start_date // pass_end_date // pass_duration // other_sat_success // cloud_cov       (optional: station, max_elevation)\n",
    "\n",
    "LABEL\n",
    "pass_success\n",
    "\n",
    "\n",
    "Steps\n",
    "\n",
    "- remove bad days\n",
    "\n",
    "- calculate pass_duration\n",
    "- calculate other sat passes\n",
    "\n",
    "- trim dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Atheras_Analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
