{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Pipeline\n",
    "\n",
    "Input:\n",
    "    - Satellite tracking data\n",
    "    - Satellite slr signal data\n",
    "    - Station sat-imagery weather data\n",
    "Output:\n",
    "    - Record of ALL satellite passes over station, weather a signal was made in that pass, and what the cloud conditons were like at the time of pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/74k69jjd0y74r977spsdpz540000gn/T/ipykernel_746/2565732241.py:3: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.\n",
      "  import pandas_profiling\n"
     ]
    }
   ],
   "source": [
    "# this script generates a reort on the cloud and slr da6ta in line of sight of the stattion\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from datetime import datetime\n",
    "from datetime import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cloud_data(station_code, sat_name, sat_id, start_date, end_date):\n",
    "\n",
    "    # read from file cloud and slr data\n",
    "    \n",
    "\n",
    "    # 3   MERGE PASS AND CLOUD DATA - SAVE TO FILE\n",
    "\n",
    "    merged_df = pd.merge(slr_merged_df, cloud_df, on='time', how='inner')\n",
    "    merged_df = merged_df[['time', 'mean_receive_amp',  'std_receive_amp', 'cloud_cov']]\n",
    "    merged_df.to_csv(f\"/Users/eugenerotherham/Documents/AtherasAnalytics/clouds-outage-prediction-main/exploration_data_analysis/data/{station_code}/satellites/{sat_name}_2022-08_2023-08_merged.txt\", sep='\\t')\n",
    "\n",
    "    cloud_slr_df = pd.read_csv(f'/Users/eugenerotherham/Documents/AtherasAnalytics/clouds-outage-prediction-main/exploration_data_analysis/data/{station_code}/satellites/{sat_name}_2022-08_2023-08_merged.txt', sep='\\t')\n",
    "    cloud_slr_df = cloud_slr_df[['time', 'mean_receive_amp', 'cloud_cov']].copy()\n",
    "\n",
    "    cloud_slr_df['time'] = pd.to_datetime(cloud_slr_df['time'])\n",
    "    cloud_slr_filtered_df = cloud_slr_df[(cloud_slr_df['time'] >= start_date) & (cloud_slr_df['time'] < end_date)]\n",
    "\n",
    "    return filtered_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def los_signal_true_false(passes_filtered_df, cloud_slr_filtered_df, sat_name, station_code):\n",
    "    los_data = []\n",
    "\n",
    "    for i in range(0, len(passes_filtered_df), 2):\n",
    "        try:\n",
    "            los_start = passes_filtered_df['time'].iloc[i].strftime('%Y-%m-%d %H:%M:%S')\n",
    "            los_end = passes_filtered_df['time'].iloc[i + 1].strftime('%Y-%m-%d %H:%M:%S')\n",
    "        except IndexError:\n",
    "            print(\"IndexError: No end of pass marker at end_date. Skipping pass...\")\n",
    "            continue\n",
    "\n",
    "        stage_cloud_slr = cloud_slr_filtered_df[\n",
    "            (cloud_slr_filtered_df['time'] >= los_start) & (cloud_slr_filtered_df['time'] <= los_end)\n",
    "        ]\n",
    "\n",
    "        average_cloud_cov = stage_cloud_slr['cloud_cov'].mean()\n",
    "\n",
    "        los_data.append({\n",
    "            'station': station_code,\n",
    "            'satellite': sat_name,\n",
    "            'pass_start_date': los_start,\n",
    "            'pass_end_date': los_end,\n",
    "            'mean_cloud': average_cloud_cov,\n",
    "        })\n",
    "\n",
    "    los_df = pd.DataFrame(los_data)\n",
    "    return los_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_turbulence_data(fits_file, lat, lon):\n",
    "    with fits.open(fits_file) as hdul:\n",
    "        data = hdul[0].data\n",
    "\n",
    "        # Define the geographical bounds\n",
    "        lat_min = -90.0\n",
    "        lat_max = 90.0\n",
    "        lon_min = -180.0\n",
    "        lon_max = 180.0\n",
    "        \n",
    "        # Get the resolution of the data\n",
    "        lat_res = (lat_max - lat_min) / data.shape[0]\n",
    "        lon_res = (lon_max - lon_min) / data.shape[1]\n",
    "\n",
    "        # Find the nearest grid point to the requested latitude and longitude\n",
    "        lat_idx = int((lat - lat_min) / lat_res)\n",
    "        lon_idx = int((lon - lon_min) / lon_res)\n",
    "\n",
    "        # Ensure the indices are within the data bounds\n",
    "        lat_idx = np.clip(lat_idx, 0, data.shape[0] - 1)\n",
    "        lon_idx = np.clip(lon_idx, 0, data.shape[1] - 1)\n",
    "\n",
    "        # Get the turbulence strength value at the specified location\n",
    "        turbulence_strength = data[lat_idx, lon_idx]\n",
    "\n",
    "        return turbulence_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data with elevation angle 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Satellites:   0%|          | 0/35 [00:00<?, ?satellite/s, Current Satellite=galileo210]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Satellites: 100%|██████████| 35/35 [38:57<00:00, 66.79s/satellite, Current Satellite=galileo209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for dataframe finished processing: see /Users/eugenerotherham/Documents/AtherasAnalytics/clouds-outage-prediction-main/exploration_data_analysis/pipeline_results/elev45_model_df.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "from contextlib import ExitStack\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "\n",
    "\n",
    "def main():\n",
    "    start_date = '2022-08-01' # START TIME OF SIMULATION\n",
    "    end_date = '2023-08-01' # END OF SIMULATION\n",
    "\n",
    "    # REQUIRMENTS MAREN AND KAREN add here more\n",
    "    ogs_latitude = 30.7128  # Example latitude for New York City\n",
    "    ogs_longitude = -74.0060  # Example longitude for New York City\n",
    "\n",
    "    # GET SATELLITE PASSES OVER EACH OGS\n",
    "    file_path = f\"PATH TO KARENS SAT PASSES FOR EACH OGS TXT FILES FOR TIMEFRAME\"\n",
    "    passes_unfil_df = pd.read_csv(file_path, sep='\\t', parse_dates=['time'])\n",
    "    passes_df = passes_unfil_df[(passes_unfil_df['time'] >= start_date) & (passes_unfil_df['time'] < end_date)]\n",
    "\n",
    "    # GET CLOUD OVER EACH OGS\n",
    "    cloud_df = pd.read_csv('FILE WITH OGS CLOUD DATA FOR TIMEFRAME', sep='\\t')\n",
    "    cloud_df['time'] = pd.to_datetime(cloud_df['time'], format = \"%Y%m%d%H%M%S\")\n",
    "    cloud_df = cloud_df.sort_values(by='time', ascending=True)\n",
    "    cloud_df = cloud_df[['time', 'cloud_cov']]\n",
    "    cloud_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # A - MERGE CLOUD WITH SATELLITE PASSES FOR EACH OGS\n",
    "\n",
    "    # GET TURBULANCE OVER EACH OGS PER PASS\n",
    "    fits_file_day = 'PATH TO TURBULANCE FITS FILE DAY'\n",
    "    fits_file_night = 'PATH TO TURBULANCE FITS FILE NIGHT'\n",
    "    ogs_turbulence_strength_day = read_turbulence_data(fits_file_day, ogs_latitude, ogs_longitude)\n",
    "    ogs_turbulence_strength_night = read_turbulence_data(fits_file_night, ogs_latitude, ogs_longitude)\n",
    "    #print(f\"Turbulence strength during the day at location ({ogs_latitude}, {ogs_longitude}): {ogs_turbulence_strength_day}\")\n",
    "    #print(f\"Turbulence strength during the night at location ({ogs_latitude}, {ogs_longitude}): {ogs_turbulence_strength_night}\")\n",
    "\n",
    "    # B - ADD THE TURBULANCE DATA TO A (based if the time of pass is night or day)\n",
    "\n",
    "    # STATIC PASS add call for isaac code\n",
    "\n",
    "    # C - ADD THE DATA TRANSFERED FOR EACH SAT PASS IN B (data = 0 where turbulance strength high)\n",
    "\n",
    "    # CALCULATE NETWORK PERFORMANCE\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Atheras_Analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
